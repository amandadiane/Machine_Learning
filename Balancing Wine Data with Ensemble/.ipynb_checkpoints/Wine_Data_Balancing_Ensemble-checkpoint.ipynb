{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based (Ensemble) Models and Handling Imbalanced Data [30 points]\n",
    "\n",
    "For this problem, we will use the wine quality dataset on which the task is a binary classification of whether a given wine is of low or high quality based on different physicochemical features.\n",
    "Â \n",
    "The dataset consists of a set of physicochemical features as inputs and the target is wine quality stored in the target column, where a value of 1 corresponds to an instance of high quality wine and -1 corresponds to an instance of low quality ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (3pts)\n",
    "Load the data from library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use wine dataset from imlearn\n",
    "from imblearn.datasets import fetch_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datasets = fetch_datasets()\n",
    "\n",
    "# Wine quality dataset contains 12 features, descriptions found here: \n",
    "# https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "data = datasets['wine_quality']\n",
    "\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Draw the class distribution of the dataset. What are possible problems if we train a classification model directly on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality observations: 3.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bc541dcc18>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries for plotting class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "high_quality_ratio = round((y == 1).sum()/(y == -1).sum() * 100, 2)\n",
    "print('Percentage of high quality observations: {}%'.format(high_quality_ratio))\n",
    "\n",
    "# color coding for 2 classes\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "## code to plot the class distribution. Hint: countplot in seaborn\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing a Random Forest classfier directly on the data (3pts)\n",
    "\n",
    "Let's first train a random forest classifier with default parameters using X_train and y_train and test the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.950204081632653\n",
      "Random forest classifier recall: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # class for random forest classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Instantiate and fit a random forest classifier to the training data\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "## Measure and print out the accuracy and recall\n",
    "test_acc = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_pred, y_test)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quetion:** Compute the recall and accuracy scores of the random forest classifier. How is the gap between the accuracy and recall scores? Provide an explanation.\n",
    "\n",
    "There is a gap of about 23%. Accuracy measures the error the classification makes, and a high accuracy rate in this case makes sense since we have a small percentage of high quality wine; most of the predictions will be correct. Recall measures the proportion of high quality wines that were correctly classified, so this random forest did a fairly good job of calling true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data balancing via Smote (6pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality counts in the balanced data: 50.0%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE #Over sampling\n",
    "import numpy as np\n",
    "\n",
    "## Instantiate smote and balance training data only\n",
    "sm = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "## Compute and print percentage of high quality wine after balancing\n",
    "percent_high_quality = round((y_resampled == 1).sum()/((y_resampled == -1).sum() + (y_resampled == 1).sum()) * 100)\n",
    "print('Percentage of high quality counts in the balanced data: {}%'.format(percent_high_quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot the distribution of balanced training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "## plot the class distribution of training data after balanced\n",
    "\n",
    "ax = sns.countplot(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain and test our random forest model on the balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.9420408163265306\n",
      "Random forest classifier recall: 0.4418604651162791\n"
     ]
    }
   ],
   "source": [
    "## Instantiate random forest and train on balanced training data\n",
    "rf_classifier_res = RandomForestClassifier(n_estimators=10)\n",
    "rf_classifier_res.fit(X_resampled, y_resampled)\n",
    "y_pred_res = rf_classifier_res.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_pred_res, y_test)\n",
    "\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_pred_res, y_test)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those without data balancing?\n",
    "\n",
    "The accuracy is very similar for both classifiers, however the recall score is lower for the resampled data. This is likely because now there are more positive examples in the data, so the classifier will get more of them wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control complexity of the model (18pts)\n",
    "\n",
    "#### Control the depth of decision trees in our ensemble (6pts)\n",
    "By default, the decision trees in random forest are expanded until all leaves are pure or until all leaves contain less than a certain number set by min_samples_split parameter. Let's try a fixed maximum depth that the tree can expand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.8114285714285714\n",
      "Random forest classifier recall: 0.5757575757575758\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth trees being 3\n",
    "rf_classifier_controlled = RandomForestClassifier(n_estimators=10, max_depth=3)\n",
    "rf_classifier_controlled.fit(X_resampled, y_resampled)\n",
    "y_pred_con = rf_classifier_controlled.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_pred_con, y_test)\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, y_pred_con)\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those in the default parameter case?\n",
    "\n",
    "Accuracy has gone down by about 13%, but recall has increase by 12%, so this classifier is getting more of the true positives correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the number of trees in the forest (6pts)\n",
    "By default, we use 10 random trees. Let's increase this number to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.8195918367346938\n",
      "Random forest classifier recall: 0.15246636771300448\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth of 3 and 100 decision trees\n",
    "rf_classifier_con2 = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "rf_classifier_con2.fit(X_resampled, y_resampled)\n",
    "y_pred_con2 = rf_classifier_con2.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_pred_con2, y_test)\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = test_recall = recall_score(y_pred_con2, y_test)\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How do the accuracy and recall change compared to those with 10 trees? What do the results imply about increasing the number of trees?\n",
    "\n",
    "The accuracy is almost the same, but the recall score dropped dramatically. This implies that increasing the number of trees can lead to overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree pruning by min_impurity_decrease (6pts)\n",
    "By default, the tree keeps expanding until the impurity is 0. However, we can specify a minimum impurity decrease amount under which nodes in the tree stop branching. RandomForestClassifier in sklearn use min_impurity_decrease for setting this threshold. Let's try that on our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy: 0.8228571428571428\n",
      "Random forest classifier recall: 0.16740088105726872\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with min impurity decrease of 0.001\n",
    "rf_classifier_min_imp = RandomForestClassifier(n_estimators=100, max_depth=3, min_impurity_decrease=0.001)\n",
    "rf_classifier_min_imp.fit(X_resampled, y_resampled)\n",
    "y_pred_min_imp = rf_classifier_min_imp.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_pred_min_imp, y_test)\n",
    "print('Random forest classifier accuracy:', test_acc)\n",
    "\n",
    "test_recall = test_recall = recall_score(y_pred_min_imp, y_test)\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How does the recall change compared to those with 10 trees and max_depth = 3?\n",
    "\n",
    "The accuracy with a min_impurity set increases by .02, so we see a little improvement there, but the recall score is still quite low compared to the classifier with 10 trees and depth of 3."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
