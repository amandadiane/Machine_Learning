{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Credit Card Fraud Detection (10 pts)\n",
    "\n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (1 pts)\n",
    "Load the data from `fraud_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent Observations:  356\n",
      "Non-Fraudulent Observations:  21337\n",
      "% Fraudulent:  0.0164\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('fraud_data.csv', sep=',')\n",
    "\n",
    "# Print the percentage of fraud observations\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "fraud_obs = len(data[data['Class'] == 1])\n",
    "non_fraud_obs = len(data[data['Class'] == 0])\n",
    "print(\"Fraudulent Observations: \", fraud_obs)\n",
    "print(\"Non-Fraudulent Observations: \", non_fraud_obs)\n",
    "print(\"% Fraudulent: \", np.round(fraud_obs/(fraud_obs+non_fraud_obs),4))\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "**Answer:** 1.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the majority class label (4pts)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? (Here accuracy is the ratio of the number of correctly classified transactions to the total number of transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuray: 0.9849416103257529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "    \n",
    "## Instantiate and fit a dummy classifier that always predict class label by the majority class of the training data\n",
    "## Use DummyClassifier in sklearn with strategy 'most_frequent\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_test_pred = dummy.predict(X_test)\n",
    "\n",
    "## Measure test accuracy of your dummy classifier\n",
    "dummy_test_acc = accuracy_score(y_test, dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier accuray:', dummy_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the accuracy of the dummy classifier look (very low, low, high, very high)? Give an explanation.*\n",
    "\n",
    "**Answer:** The accuracy of the dummy classifier is very high (98.5%). This is because there are very few fraud cases in the data compared to non-fraud cases, so it's easy for the dummy variable to achieve high accuracy by assuming everything in non-fraudulent. This results in only misclassifying the 1.6% of the data that is actually fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How many fraudulent transactions are correctly classified? (This is the **recall** score/measure)*\n",
    "\n",
    "**Answer:** 0 fraudulent transactions were correctly classified - the recall score is 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Measure test recall score of your dummy classifier\n",
    "dummy_test_recall = recall_score(y_test, dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier recall:', dummy_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the recall of the dummy classifier look (very low, low, high, very high)? Give an explanation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a logistic regression model (3pts)\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9964658881376767\n",
      "Logistic classifier recall: 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "## Instantiate a logistic regression model and fit to the training data\n",
    "logR = LogisticRegression(random_state=0, solver='liblinear')\n",
    "logR.fit(X_train, y_train)\n",
    "logR_test_pred = logR.predict(X_test)\n",
    "\n",
    "## Measure test accuracy \n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results of logistic regression with those of the above dummy classifier*\n",
    "\n",
    "**Answer:** When comparing the results, I see that the logistic regression model has improved accuracy (achieving 99.6% compared to the dummy classifier's 98.5%, but more importantly the log reg model also has a recall score of 79.6% compared to the dummy model's 0%. This means that the log reg model is correctly labeling fraud cases 79.6% of the time, rather than never."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for selecting hyperparameters for Logistic Regression (2pts)\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Define the grid of logistic regression parameters\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10, 100]}\n",
    "model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "    \n",
    "## Perform grid search CV to find best model parameter setting\n",
    "cmodel = GridSearchCV(model, param_grid=parameters, cv=3, scoring='recall', n_jobs=-2, \n",
    "                      return_train_score=True)\n",
    "cmodel.fit(X_train, y_train.ravel());\n",
    "\n",
    "cmodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9967732022126613\n",
      "Logistic classifier recall: 0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Fit logistic regression with best parameters to the entire training data\n",
    "model = LogisticRegression(penalty=cmodel.best_params_['penalty'], C=cmodel.best_params_['C'], \n",
    "                           random_state=0, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "logR_test_pred = model.predict(X_test)\n",
    "\n",
    "## Measure test accuracy\n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results with that of logistic regression with default parameters*\n",
    "\n",
    "**Answer:** The accuracy stayed the same across the default parameters and the best parameters chosen by the grid search. The recall score increased for the model that used the best parameters to .8163 (up from .7959 in the default model), which means more of the fraud cases were correctly labeled."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
